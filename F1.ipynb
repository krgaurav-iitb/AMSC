{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy\n",
    "def f(a,b):\n",
    "    \n",
    "    p=math.pi/10;\n",
    "    l=[0,p,2*p,3*p,4*p,5*p]\n",
    "    res=0\n",
    "    \n",
    "    for x in l:\n",
    "        res+=pow((max(a*x-b,0)-1+math.cos(x)),2)\n",
    "    return res/12\n",
    "\n",
    "def diffrelu(a,x,b):\n",
    "    \n",
    "    return numpy.sign(max((a*x-b),0))\n",
    "\n",
    "def gradfa(a,b):\n",
    "    \n",
    "    p=math.pi/10;\n",
    "    l=[0,p,2*p,3*p,4*p,5*p]\n",
    "    res=0\n",
    "    \n",
    "    for x in l:\n",
    "        res+=((max(a*x-b,0)-1+math.cos(x))*diffrelu(a,x,b)*x)\n",
    "    return res/6\n",
    "\n",
    "def gradfb(a,b):\n",
    "    \n",
    "    p=math.pi/10;\n",
    "    l=[0,p,2*p,3*p,4*p,5*p]\n",
    "    res=0\n",
    "    \n",
    "    for x in l:\n",
    "        res+=((max(a*x-b,0)-1+math.cos(x))*diffrelu(a,x,b)*-1)\n",
    "    return res/6\n",
    "\n",
    "def gradfxa(a,b,x):\n",
    "    \n",
    "    p=math.pi/10;\n",
    "    res=((max(a*x-b,0)-1+math.cos(x))*diffrelu(a,x,b)*x)\n",
    "    return res/6\n",
    "\n",
    "def gradfxb(a,b,x):\n",
    "    \n",
    "    p=math.pi/10;\n",
    "    res=((max(a*x-b,0)-1+math.cos(x))*diffrelu(a,x,b)*-1)\n",
    "    return res/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8634543941368049\n",
      "0.3758725037260964\n"
     ]
    }
   ],
   "source": [
    "#evaluating minimizer and minima through analytical formula\n",
    "\n",
    "p=math.pi/10\n",
    "l=[2*p,3*p,4*p,5*p]\n",
    "term2=0\n",
    "term1=0\n",
    "term3=0\n",
    "\n",
    "temp1=0\n",
    "temp2=0\n",
    "\n",
    "for x in l:\n",
    "    temp1+=(1-math.cos(x))\n",
    "    temp2+=x\n",
    "\n",
    "#for calculating a\n",
    "for x in l:\n",
    "    term1+=((temp1/6)*x)\n",
    "    term2+=((1-math.cos(x))*x)\n",
    "    term3+=(x-temp2/6)\n",
    "\n",
    "a=(term2-term1)/term3\n",
    "print((term2-term1)/term3)\n",
    "\n",
    "#for calculating b\n",
    "term4=0\n",
    "term5=0\n",
    "\n",
    "for x in l:\n",
    "    term4+=((a)*x)\n",
    "    term5+=((1-math.cos(x)))\n",
    "b=(term4-term5)/4\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.000363464353009919"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradDescent(s):\n",
    "    \n",
    "    a=1\n",
    "    b=0\n",
    "    \n",
    "    preva=0\n",
    "    prevb=0\n",
    "    \n",
    "    step =s\n",
    "    count =0\n",
    "    \n",
    "    while((abs((a-preva))>0.00000000001 and abs((b-prevb))>0.0000000001) or count==0):\n",
    "        #step=0.99*step\n",
    "        preva=a\n",
    "        prevb=b\n",
    "        #print(gradfa(a,b))\n",
    "        #print(gradfb(a,b))\n",
    "        \n",
    "        a=a-(step*gradfa(a,b))\n",
    "        b=b-(step*gradfb(a,b))\n",
    "        count+=1\n",
    "    if( b>(a*5*math.pi/10)):\n",
    "        \n",
    "        print(\"Flat region\")\n",
    "    print(a)\n",
    "    print(b)\n",
    "    print(f(a,b))\n",
    "    print(\"number of iterations= \",count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8612890147830452\n",
      "0.3734915447526051\n",
      "0.0003632715310289964\n",
      "number of iterations=  52\n"
     ]
    }
   ],
   "source": [
    "gradDescent(2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8612890141385451\n",
      "0.3734915440904555\n",
      "0.0003632715310289978\n",
      "number of iterations=  122\n"
     ]
    }
   ],
   "source": [
    "gradDescent(2.413)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flat region\n",
      "-0.5976836229897233\n",
      "-0.08863668559274276\n",
      "0.1411754122798186\n",
      "number of iterations=  5\n"
     ]
    }
   ],
   "source": [
    "gradDescent(2.414) #Minimal step size to reach flat region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def stochGradDescent():\n",
    "    \n",
    "    a=1\n",
    "    b=0\n",
    "    \n",
    "    preva=0\n",
    "    prevb=0\n",
    "    \n",
    "    step =6\n",
    "    count =0\n",
    "    \n",
    "    p=math.pi/10\n",
    "    for i in range(1,15):\n",
    "        step=step/pow(1.2,i)\n",
    "        nn= math.ceil((15*pow(1.2,i)/i))\n",
    "        \n",
    "        for j in range(nn):\n",
    "            #step=0.99*step\n",
    "            preva=a\n",
    "            prevb=b\n",
    "            #print(gradfa(a,b))\n",
    "            #print(gradfb(a,b))\n",
    "            l=[0,p,2*p,3*p,4*p,5*p]\n",
    "\n",
    "            n=random.randint(0,5)\n",
    "\n",
    "            a=a-(step*gradfxa(a,b,l[n]))\n",
    "            b=b-(step*gradfxb(a,b,l[n]))\n",
    "            count+=1\n",
    "        \n",
    "    if( b>(a*5*math.pi/10)):\n",
    "        \n",
    "        print(\"Flat region\")\n",
    "    print(a)\n",
    "    #print(count)\n",
    "    print(b)\n",
    "    print(f(a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8754939372496217\n",
      "0.3926012096200698\n",
      "0.0003756306762194008\n"
     ]
    }
   ],
   "source": [
    "stochGradDescent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005200047197720893"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
